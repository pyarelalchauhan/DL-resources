{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1V3qJxF0_Xv",
        "outputId": "e810f4b6-3c66-491b-8ddc-a8bd782d0345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define your network architecture\n",
        "class OneHiddenLayerNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(OneHiddenLayerNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(3, 4)  # Input layer to hidden layer\n",
        "        self.fc2 = nn.Linear(4, 2)  # Hidden layer to output layer\n",
        "\n",
        "        # Manually set weights and biases\n",
        "        self.fc1.weight.data = torch.tensor([[1.0, -1.0, 1.0],   # Weights from input to hidden layer\n",
        "                                             [1.0, 1.0, 0.0],\n",
        "                                             [0.0, 1.0, 1.0],\n",
        "                                             [1.0, 0.0, 1.0]])\n",
        "        self.fc1.bias.data = torch.tensor([-5.0, 0.0, 1.0, -2.0])  # Biases for hidden layer\n",
        "\n",
        "        self.fc2.weight.data = torch.tensor([[1.0, 1.0, -1.0, 0.0],\n",
        "                                             [0.0, 0.0, 1.0, -1.0]])  # weights for the layer 2 ( 2*4)\n",
        "        self.fc2.bias.data = torch.tensor([0.0, 1.0])      # bias for output layer (2*1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))  # Applying ReLU activation after the first layer\n",
        "        x = torch.relu(self.fc2(x))  # Output layer with relu activation\n",
        "        return x\n",
        "\n",
        "# Create an instance of the network\n",
        "net = OneHiddenLayerNetwork()\n",
        "\n",
        "# Print the weights and biases of each layer\n",
        "print('Weights and biases of each layer:')\n",
        "print('Weight of the first layer:')\n",
        "print(net.fc1.weight.data)\n",
        "print('Bias of the first layer:')\n",
        "print(net.fc1.bias.data)\n",
        "print('Weight of the second layer:')\n",
        "print(net.fc2.weight.data)\n",
        "print('Bias of the second layer:')\n",
        "print(net.fc2.bias.data)\n",
        "# Print the modified network\n",
        "print('Network structure:')\n",
        "print(net)\n",
        "\n",
        "# Now let's create the input vector x\n",
        "x = torch.tensor([[2.0, 1.0, 3.0]])\n",
        "\n",
        "# Forward pass through the first layer\n",
        "wx_plus_b_fc1 = torch.matmul(net.fc1.weight.data, x.t()) + net.fc1.bias.data.view(4, 1)\n",
        "print('wx + b for the first layer:\\n', wx_plus_b_fc1)\n",
        "\n",
        "# Applying ReLU activation to wx + b for the first layer\n",
        "relu_output = torch.relu(wx_plus_b_fc1)\n",
        "print('ReLU applied to wx + b for the first layer:\\n', relu_output)\n",
        "\n",
        "# Forward pass through the second layer\n",
        "wx_plus_b_fc2 = torch.matmul(net.fc2.weight.data, relu_output) + net.fc2.bias.data.view(2, 1)\n",
        "print('wx + b for the second layer:\\n', wx_plus_b_fc2)\n",
        "\n",
        "# Applying ReLU activation to wx + b for the first layer\n",
        "relu_output_fc2 = torch.relu(wx_plus_b_fc2)\n",
        "print('ReLU applied to wx + b for the first layer:\\n', relu_output_fc2)\n",
        "\n",
        "# # Forward pass through the network\n",
        "output = net(x)\n",
        "print('Output after forward pass through the network:\\n', output.view(2,1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFULqtz_1Qko",
        "outputId": "562dcc80-4194-48e5-c6f8-8728a43d9f6e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights and biases of each layer:\n",
            "Weight of the first layer:\n",
            "tensor([[ 1., -1.,  1.],\n",
            "        [ 1.,  1.,  0.],\n",
            "        [ 0.,  1.,  1.],\n",
            "        [ 1.,  0.,  1.]])\n",
            "Bias of the first layer:\n",
            "tensor([-5.,  0.,  1., -2.])\n",
            "Weight of the second layer:\n",
            "tensor([[ 1.,  1., -1.,  0.],\n",
            "        [ 0.,  0.,  1., -1.]])\n",
            "Bias of the second layer:\n",
            "tensor([0., 1.])\n",
            "Network structure:\n",
            "OneHiddenLayerNetwork(\n",
            "  (fc1): Linear(in_features=3, out_features=4, bias=True)\n",
            "  (fc2): Linear(in_features=4, out_features=2, bias=True)\n",
            ")\n",
            "wx + b for the first layer:\n",
            " tensor([[-1.],\n",
            "        [ 3.],\n",
            "        [ 5.],\n",
            "        [ 3.]])\n",
            "ReLU applied to wx + b for the first layer:\n",
            " tensor([[0.],\n",
            "        [3.],\n",
            "        [5.],\n",
            "        [3.]])\n",
            "wx + b for the second layer:\n",
            " tensor([[-2.],\n",
            "        [ 3.]])\n",
            "ReLU applied to wx + b for the first layer:\n",
            " tensor([[0.],\n",
            "        [3.]])\n",
            "Output after forward pass through the network:\n",
            " tensor([[0.],\n",
            "        [3.]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iAiL5txy9F_a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}