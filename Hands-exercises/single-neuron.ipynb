import torch
import torch.nn as nn
print(torch.__version__)
# 1. Single Neuron

# Define your network
net = nn.Linear(3, 1) # Single input feature (3,1) and single neuron

# Manually set weights
weights = torch.tensor([[1.0, -1.0, 1.0]]) # 1*3 weight matrix 
biases = torch.tensor([-5.0]) # 1 bias

# Assign weights and biases
net.weight.data = weights
net.bias.data = biases

# Print the modified network
print('network structure:')
print(net)
print('\nWeight of the network:')
print(net.weight)
print('\nBias of the network:')
print(net.bias)

# Now lets create the input vector x
x = torch.tensor([[2.0,1.0,3.0]])
print("input = x :\n ",x)
z = torch.mm(net.weight,x.t()) + net.bias;
print('w x + b :\n',z)

# Applying ReLU activation
output = torch.relu(z)
print('ReLU applied to w x + b:\n', output)
